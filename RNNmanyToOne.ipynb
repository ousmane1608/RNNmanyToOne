{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation from scratch d'un RNN de type many to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function sigmoid that applies the sigmoid activation function\"\"\"\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\"\"\"function tangente hyperbolique that applies the hyperbolic tangent activation function\"\"\"\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcule des etats interne\n",
    "def stape_interne(x, u, w, h, b, activation=\"tanh\"):\n",
    "    if activation == \"sigmoid\":\n",
    "        return sigmoid(u.dot(x) + w.dot(h) + b)\n",
    "    elif activation == \"tanh\":\n",
    "        return tanh(u.dot(x) + w.dot(h) + b)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "def H(self,X, u, w, h, b, size_output: int = None, activation=\"tanh\"):\n",
    "  if size_output is None:\n",
    "    result = np.zeros((u.shape[0], X.shape[1]))\n",
    "  elif size_output < X.shape[1]:\n",
    "    result = np.zeros((u.shape[0], size_output))\n",
    "  else:\n",
    "    result = np.zeros((u.shape[0], X.shape[1]))\n",
    "   \n",
    "  for i in range(X.shape[1]):\n",
    "    if i==0:\n",
    "       h =np.random.random(size=(self.w.shape[0],1) )\n",
    "    h = stape_interne(X[:, i:i+1], u, w, h, b)\n",
    "    result[:, i:i+1] = h\n",
    "  return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class Couche:\n",
    "  def __init__(self,input_size:tuple, state_size:tuple, output_size:int = None):\n",
    "    self.u  = np.random.random(size =(state_size[0],input_size[0]))\n",
    "    self.w =np.random.random(size=(state_size[0],state_size[0]))\n",
    "    self.h0 =np.random.random(size=(self.w.shape[0],1) )\n",
    "    self.b  = np.random.random(1)\n",
    "    self.output_size = output_size\n",
    "    self.v = np.random.random(size=(output_size,state_size[0]))\n",
    "  def sigmoid(self,x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "  def tanh(self,x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "  def stape_interne(self,x,h,activation=\"tanh\"):\n",
    "      if activation == \"sigmoid\":\n",
    "          return sigmoid(self.u.dot(x) + self.w.dot(h) + self.b)\n",
    "      elif activation == \"tanh\":\n",
    "          return tanh(self.u.dot(x) + self.w.dot(h) + self.b)\n",
    "      else:\n",
    "          raise ValueError(\"Invalid activation function\")\n",
    "\n",
    "\n",
    "  def H(self,X,activation=\"tanh\"):\n",
    "    \n",
    "    result = np.zeros((self.v.shape[0], X.shape[1]))\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "      if i==0:\n",
    "        h = stape_interne(X[:, i:i+1], self.u, self.w, self.h0, self.b)\n",
    "      else:\n",
    "        h = stape_interne(X[:, i:i+1], self.u, self.w, h, self.b)\n",
    "      \n",
    "      state = np.dot(self.v,h)\n",
    "      result[:, i:i+1] = state\n",
    "    if self.output_size is not None:\n",
    "      if self.output_size < X.shape[1]:\n",
    "        return result[:,-self.output_size:]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30694575]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = Couche((4,5),(4,1),1)\n",
    "X= np.array([[1,20,1,1,-0.111],[2,2,-2,0.05,2],[3,40,3,0.9,3],[0.76,4,-56,4,4]])\n",
    "rnn.H(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "  def __init__(self):\n",
    "    self.couches = []\n",
    "  def input(self,c1: Couche):\n",
    "    self.couches.append(c1)\n",
    "  def hidLayer(self, state_size:tuple,output_size:int):\n",
    "    index_max = len(self.couches) -1\n",
    "    self.couches.append(Couche(input_size=(self.couches[index_max].v.shape[0],output_size),state_size=state_size,output_size=output_size))\n",
    "\n",
    "  def fit(self,X):\n",
    "    for objets in self.couches:\n",
    "      X = objets.H(X)\n",
    "    return X\n",
    "  # mise a jour des parametres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RNN.hidLayer() missing 1 required positional argument: 'output_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m rx\u001b[38;5;241m.\u001b[39minput(Couche(input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m),state_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m1\u001b[39m),output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m rx\u001b[38;5;241m.\u001b[39mhidLayer(state_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m),output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m rx\u001b[38;5;241m.\u001b[39mfit(X)\n",
      "\u001b[1;31mTypeError\u001b[0m: RNN.hidLayer() missing 1 required positional argument: 'output_size'"
     ]
    }
   ],
   "source": [
    "# test la class RNN\n",
    "rx = RNN()\n",
    "rx.input(Couche(input_size=(4,5),state_size=(10,1),output_size=3))\n",
    "rx.hidLayer(state_size=(3,1),output_size=2)\n",
    "rx.hidLayer(state_size=(2,1),output_size=1)\n",
    "rx.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
